---
title: Aspera
description: Basic guide for deploying the Fast File Transfer
keywords: 'ibm, install, integration, Aspera, High Speed File Transfer'
---

<InlineNotification>

Version 2020.2 is out for Cloud Pak for Ingegration.  This version is the first to feature Operators and has significant changes to the deployment and operations.  Please refer to the [Knowledge Center](https://www.ibm.com/support/knowledgecenter/en/SSGT7J_20.2/overview.html) while we update this playbook.  Thanks!

</InlineNotification>

<AnchorLinks>
  <AnchorLink>Introduction</AnchorLink>
  <AnchorLink>Prepare Installation</AnchorLink>
  <AnchorLink>Begin Installation</AnchorLink>
  <AnchorLink>Validate installation</AnchorLink>
</AnchorLinks>

### **Introduction**
This page contains guidance on how to configure the Aspera release for
both on-prem and IBM Cloud.

<ul>
</ul>

### **Prepare Installation**

1. **Change project to aspera**
   ```
   oc project aspera
   ```
2. **Use Node Labels:**

    In order to ensure high availability, the Aspera Swarm services will
    attempt to create a configurable number of pods on each node in the
    Kubernetes cluster. The nodes on which the receiver pods are running
    can be restricted via the nodeLabels values.

    For example, the following would restrict pods to nodes with
    the `node-role.kubernetes.io/ascp=true` label or
    `node-role.kubernetes.io/noded=true` label.

    ```
    ascpSwarm:
    config:
        nodeLabels:
        node-role.kubernetes.io/ascp: "true"

    nodedSwarm:
    config:
        nodeLabels:
        node-role.kubernetes.io/noded: "true"
    ```

    Label Nodes using the command

    ```
    oc label node &lt;node-name&gt; node-role.kubernetes.io/&lt;role&gt;=true
    ```

3. **Additional RBAC Requirements:**

    The following RBAC resources are also required before you deploy the
    chart. Use the command `oc create -f &lt;filename.yaml&gt;`

    - **Cluster Admin**
      - [ClusterRole](/assets/img/integration/aspera/files/cluster-admin-clusterrole.yaml)
    - **Namespace User**
      Substitute {{ NAMESPACE }} with the namespace the chart will be deployed in.
      - [ClusterRoleBinding](/assets/img/integration/aspera/files/namespace-user-clusterrole.yaml)
      - [Role](/assets/img/integration/aspera/files/namespace-user-role.yaml)
      - [RoleBinding](/assets/img/integration/aspera/files/namespace-user-rolebinding.yaml)
      - [RoleBinding](/assets/img/integration/aspera/files/hsts-prod-rolebinding.yaml)
      - [ServiceAccount](/assets/img/integration/aspera/files/apsera-sa-role.yaml) - Set to `ibm-entitlement-key` if using entitled registry or if offline use the `deployer-dockercfg-XX` secret in your namespace.  Use `oc get secrets` to get the value.
      - [Secret Generation Role](/assets/img/integration/aspera/files/secret-gen-role.yaml)
      - [Secret Generation RoleBinding](/assets/img/integration/aspera/files/secret-gen-rolebinding.yaml)
      - [Secret Generation ServiceAccount](/assets/img/integration/aspera/files/secret-gen-sa.yaml)

4. **Create the secrets**

   Make sure you have copied your aspera license key to the location
   where you will be creating the secrets.  The following command assumes
   it is named `aspera-license`.

   ```
   oc create secret generic aspera-server --from -file=ASPERA_LICENSE="./aspera-license" --from-literal=TOKEN_ENCRYPTION_KEY="my_encryption_key"

   kubectl create secret generic asperanode-nodeadmin --from-literal=NODE_USER="myuser" --from-literal=NODE_PASS="mypassword"

   kubectl create secret generic asperanode-accesskey --from-literal=ACCESS_KEY_ID="my_access_key" --from-literal=ACCESS_KEY_SECRET="my_access_key_secret"
   ```

<ul>
</ul>

### **Begin Installation**
1. Go to CP4I Platform Home. Click **Create instance** inside
the **Aspera** tile.
1. A window will pop up with a description of the requirements for
installing. Click **Continue** to the helm chart deployment configuration.
2. Click **Overview** to view the chart information and pre-reqs that
were covered in [Prepare Installation](#prepare-installation).
3. Click **Configure**
4. Enter the Helm release name. In our example, **Aspera-1**
5. Enter Target Namespace - **Aspera**
6. Select a Cluster - **local-cluster**.
7. Tick the license agreement checkbox.
8. Under Parameters -> Quick start
   1. Ingress - icp-proxy address defined during icp / common-services installation - icp-proxy.\&lt;openshift-router-domain&gt;
   2. Aspera Node - Server Secret - the secret created using the license - `aspera-server`
   3. Aspera Event Journal - Kafka Host - use hostname of bootstrap server of existing eventstreams installation. Get this value from the Eventstreams web ui.
   4. Aspera Rproxy - address of cluster proxy.  This can be configured later if need be.
9.  Click All Parameters
10. Uncheck production usage
11. Image Pull Secret - the secret used to pull images for install from
the docker registry. Set to `ibm-entitlement-key` if using entitled
registry or if offline use the `deployer-dockercfg-XX` secret in your
namespace.
12. Scroll down to the Redis section.
13. Check Persistence Enabled.
14. Check Use dynamic provisioning.
15. Storage Class Name - enter storage class for file storage
16. Image Pull Secret - same as step 11.
17. Scroll down to Persistence
18. Enter the same Storage Class Name as step 15
19. Proceed to the section Aspera Node
20. Node Admin Secret - enter the nodeadmin secret created in the preious
section - `asperanode-nodeadmin`
21. Access Key Secret - enter the access key secret created in the previous
section - `asperanode-accesskey`
22. Proceed to the section - Aspera Event Journal
23. Kafka Port - change to Kafka port found in Eventstreams bootstrapi
server.
24. Proceed to section Ascp Swarm
25. Node Labels - enter the node labels created in the previous section
for identifying ascp swarm nodes -
   ```
   {-node-role.kubernetes.io/ascp: true}
   ```
26. Proceed to section - Noded Swarm
27. Node Labels - set to the node label created for noded from the previous section
   ```
   {-node-role.kubernetes.io/noded: "true"}
   ```
28. Scroll to section - Sch
29. Image Pull Secret - the secret used to pull images for install from
the docker registry. Set to `ibm-entitlement-key` if using entitled
registry or if offline use the `deployer-dockercfg-XX` secret in your
namespace.

<ul>
</ul>

### **Validate installation**

1. View all pods running
    ```
    NAME                                                       READY     STATUS      RESTARTS   AGE
    aspera-1-aspera-hsts-aej-d8c5b5569-24vh8                   1/1       Running     0          3m
    aspera-1-aspera-hsts-aej-d8c5b5569-68nvj                   1/1       Running     0          3m
    aspera-1-aspera-hsts-aej-d8c5b5569-v5xgb                   1/1       Running     0          3m
    aspera-1-aspera-hsts-ascp-loadbalancer-75849464b-lq8lz     1/1       Running     0          3m
    aspera-1-aspera-hsts-ascp-swarm-54c98cb6bb-hznw5           2/2       Running     0          3m
    aspera-1-aspera-hsts-create-access-key-v1-24hdg            0/1       Completed   0          3m
    aspera-1-aspera-hsts-http-proxy-8b86df4f-8hd6d             1/1       Running     0          3m
    aspera-1-aspera-hsts-node-api-796f5c8ccc-r9xs2             2/2       Running     0          3m
    aspera-1-aspera-hsts-node-master-788774bbc7-8sl2s          2/2       Running     0          3m
    aspera-1-aspera-hsts-noded-loadbalancer-844977799b-f4gd6   1/1       Running     0          3m
    aspera-1-aspera-hsts-noded-swarm-6b8498fd-slj8g            2/2       Running     0          3m
    aspera-1-aspera-hsts-prometheus-endpoint-bc5974d79-4fv4t   2/2       Running     0          3m
    aspera-1-aspera-hsts-prometheus-endpoint-bc5974d79-d426s   2/2       Running     0          3m
    aspera-1-aspera-hsts-prometheus-endpoint-bc5974d79-t7f8l   2/2       Running     0          3m
    aspera-1-aspera-hsts-stats-5c5c8cc8fc-c2gbr                2/2       Running     0          3m
    aspera-1-aspera-hsts-stats-5c5c8cc8fc-lcbxr                2/2       Running     0          3m
    aspera-1-aspera-hsts-stats-5c5c8cc8fc-qpj5l                2/2       Running     0          3m
    aspera-1-aspera-hsts-tcp-proxy-748b6bb64-j478m             1/1       Running     0          3m
    aspera-1-redis-ha-sentinel-0                               1/1       Running     0          3m
    aspera-1-redis-ha-sentinel-1                               1/1       Running     0          2m
    aspera-1-redis-ha-sentinel-2                               1/1       Running     0          1m
    aspera-1-redis-ha-server-0                                 1/1       Running     0          3m
    aspera-1-redis-ha-server-1                                 1/1       Running     0          2m
    aspera-1-redis-ha-server-2                                 1/1       Running     0          2m
    ```
